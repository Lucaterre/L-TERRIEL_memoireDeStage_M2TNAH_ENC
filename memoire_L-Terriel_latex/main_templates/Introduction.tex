\part*{Introduction}
\addcontentsline{toc}{part}{Introduction}
\markboth{Introduction}{Introduction}

Depuis la caractérisation de certains types d'écritures par le moine bénédictin mauriste Jean Mabillon (1632-1707) dans son traité de diplomatique \textit{De re diplomatica} considéré comme un temps fondateur pour la paléographie, en passant par la traduction des hiéroglyphes en 1822 par Jean-François Champollion (1790-1832); lire, comprendre et déchiffrer les écritures pour analyser son passé et envisager l'avenir est une constante chez l'homme. Au début du XXI$^{e}$ siècle, un nouveau cap a été franchi dans la tentative de décoder et de présenter les sources anciennes de l'histoire avec l'émergence des technologies numériques.\\

D'un côté les institutions patrimoniales ont massifié la numérisation et la mise en ligne de leurs collections sous la forme de bases de données qui continuent de croître; de l'autre la discipline informatique a envisagé le moyen de doter les machines d'une \inquote{intelligence} proche des capacités humaines, comme la possibilité de voir, de lire et de reproduire un texte rendu possible par l'apprentissage des réseaux de neurones artificiels. Enfin les sciences humaines et sociales, tentent de comprendre et de tirer parti de ces innovations afin d'envisager d'autres approches méthodologiques sur les sources. Depuis 2018, le projet Lectaurep (LECTure AUtomatique de REPertoires) se situe à la confluence de ces trois domaines en essayant de faire dialoguer les archivistes, les ingénieur(e)s en informatique et les chercheuses et les chercheurs en sciences humaines pour trouver de nouveaux moyens de rendre les fonds du département du Minutier central des notaires parisiens des Archives nationales exploitables à distance pour des publics désormais familiers des outils numériques.\\

Le projet Lectaurep\footnote{Projet Lectaurep, Archives nationales, URL : \url{http://www.archives-nationales.culture.gouv.fr/l-intelligence-artificielle-et-le-patrimoine}}, qui est entré dans sa troisième phase en novembre 2019, vise a repenser l'usage qui est fait actuellement des répertoires de notaires, l'une des sources du Minutier central les plus consultées. Alliant des domaines de l'intelligence artificielle comme la reconnaissance d'écriture manuscrite (HTR) et la recherche d'informations (NER), Lectaurep utilise  la plate-forme \textit{eScriptorium}\footnote{\textit{eScriptorium}, URL : \url{https://escripta.hypotheses.org/}} (PSL/eScripta), qui est basée sur le logiciel OCR/HTR appelé \textit{Kraken}\footnote{\textit{Kraken}, URL : \url{http://kraken.re/}}. Les applications à terme de la vision par ordinateur sont nombreuses pour les archives : recherche en texte intégral et extraction d'informations dans plus de deux milles répertoires comptant trois cents à cinq cents pages chacun, outil de transcription collaboratif, outils d'analyses quantitatives (fiscalité notariale) et de visualisation de l'activité géographique des notaires, édition numérique des répertoires etc. Les Archives nationales (Ministère de la Culture) se sont associées à Inria et à son équipe-projet ALMAnaCH dans le cadre d'une convention-cadre pour mettre en oeuvre ces technologies.\\

Inria, anciennement Institut national de recherche en informatique et automatique, est un établissement public à caractère scientifique et technologique placé sous la double tutelle du ministère de l'Enseignement supérieur, de la Recherche et de l'innovation et du ministère de l'Économie et des Finances. Créé le 3 janvier 1967 à l'occasion du \inquote{plan calcul}\footnote{\inquote{Notre histoire | Inria}, URL : \url{https://www.inria.fr/fr/notre-histoire}}, Inria accompagne la recherche en informatique et en mathématiques et crée des partenariats privés ou publics assurant les transferts de technologies. Depuis 2018, Inria fait figure de plate-forme stratégique dans le développement de l'intelligence artificielle. A côté de ces missions, Inria assure la valorisation des sciences de l'information et de la communication (Mooc), monte des \textit{startups} technologiques et édite des logiciels \textit{open-source}\footnote{\inquote{Dix logiciels stars d'Inria | Inria}, URL : \url{https://www.inria.fr/fr/dix-logiciels-stars-dinria}}. Inria compte trois mille cinq cents chercheurs, chercheuses et ingénieur(e)s répartis en deux cents équipes-projet dans huit centres de recherche axés sur des domaines scientifiques tels que la science des données, le calcul haute performance, l'intelligence artificielle, l'informatique théorique, la sécurité informatique etc.  ALMAnaCH (\textit{Automatic Language Modelling and Analysis \& Computational Humanities}) est l'une des équipes-projet de Inria spécialisée dans le développement de logiciels et de ressources en traitement automatique du langage naturel (TAL) en s'appuyant sur les méthodes récentes d'apprentissage profond. L'équipe accompagne les chercheurs, les chercheuses et les instituions patrimoniales dans les transitions technologiques qu'impliquent le récent paradigme des humanités computationnelles\footnote{ALMAnaCH-Équipe-projet Inria, URL : \url{https://team.inria.fr/almanach/fr/}}. L'équipe est coordonnée par le responsable scientifique, Benoît Sagot, et des membres permanents, Laurent Romary, Djamé Seddah, Éric Villemonte de La Clergerie et Rachel Bawden.\\

Le présent mémoire rend compte du stage qui s'est déroulé du 30 mars 2020 au 31 juillet 2020 au sein de l'équipe ALMAnaCH d'Inria pour le projet Lectaurep. Cependant, le contexte lié à l'épidémie de COVID-19, m'a obligé, comme la plupart des stagiaires et des salarié(e)s à effectuer la totalité de mon stage à distance avec comme principale interlocutrice Alix Chagué, ingénieure en recherche et tutrice de stage. Mon intérêt pour les archives m'avait poussé à effectuer un stage en juin 2019 au Minutier central des Archives nationales où j'avais découvert les fonds ainsi que le projet Lectaurep. L'envie de mettre à profit mes compétences informatiques acquises tout au long de l'année ainsi que de découvrir des aspects de développement plus poussés dans les domaines de la \textit{Datascience} et du TAL m'a conforté dans le choix de ce stage.\\

Le projet Lectaurep, qui a connu trois phases d'essais, s'appuie sur des outils en cours de développement comme la plate-forme \textit{eScriptorium}, qui demandent un soutien régulier pour maintenir les principales fonctionnalités. Dans ce contexte d'expérimentation des outils et dans la recherche d'innovations; en dehors d'un cahier des charges à mettre en oeuvre et d'une mise en production imminente d'une chaîne de traitement arrêtée, j'ai cherché à savoir comment mettre en place des outils et des formules pour représenter, structurer et évaluer les données manipulées jusqu'à présent dans Lectaurep.\\ 

A côté des missions portant sur la valorisation du projet et la prise en main de \textit{Kraken} par l'intermédiaire d'entraînements de modèles de transcriptions, mes missions principales étaient les suivantes : 
\begin{itemize}
    \item Réfléchir à la mise en place d'un format pivot XML-TEI pour structurer les données lors de l'import des images et de l'export des transcriptions de vérités terrains dans \textit{eScriptorium}, tout en soulignant les avantages de la TEI dans la poursuite du projet.
    \item Développer un outil généralisable à d'autres projets HTR, nécessaire dans la suite du projet Lectaurep, pour évaluer les modèles de transcription et tester cet outil sur des jeux de données Lectaurep. 
\end{itemize}

Si nous reviendrons, dans un premier temps, sur les aspects historiques et technologiques inhérents au projet Lectaurep, c'est pour mieux appréhender les types de données, métadonnées et les contraintes posées par les documents et les Archives nationales. Cependant, dans un second temps, nous verrons que la mise en place d'une première version d'un fichier XML-TEI pivot peut permettre de structurer ces métadonnées et de les récupérer lors des imports et des exports au sein de le plate-forme \textit{eScriptorium}. Dès lors, dans une dernière partie, nous aborderons la création \textit{ex-nihilo} d'un outil en Python, \textit{Kraken-Benchmark}, pour permettre l'évaluation et l'analyse des modèles HTR à partir de métriques. Les résultats pouvant être intégrés au fichier pivot XML-TEI et/ou dans la chaîne de traitement globale du projet.


